{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This program implements the retrieval of XKCD comics\n",
    "Written by Tim Burke and Anuj Ramakrishnan\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xlwt\n",
    "import xlrd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk import word_tokenize # Tokenization tool\n",
    "\n",
    "\n",
    "########################################################################################################################\n",
    "# Read in the data \n",
    "########################################################################################################################\n",
    "\n",
    "df = pd.read_csv('data/comic_final_data.csv',encoding='UTF-8')\n",
    "df = df.fillna(\" \")\n",
    "df[\"all_text\"] = df[\"title\"] + \" \" + df[\"topic_category\"] + \" \" + df[\"title_text\"] + \" \" + df[\"explanation\"] + \" \" + df[\"transcript\"]\n",
    "\n",
    "# To remove duplicates of comics in multiple categories, first find all categories for all comics\n",
    "def get_all_categories(row):\n",
    "    categories = df['topic_category'].loc[df['url'] == row['url']]\n",
    "    cats = categories.str.cat(sep=' ')\n",
    "    return cats\n",
    "df['all_categories'] = df.apply(get_all_categories,axis=1)\n",
    "\n",
    "# Now we remove duplicate comics, keeping only 1 of each\n",
    "df = df.drop_duplicates(subset='url',keep='first')\n",
    "df = df.drop('topic_category',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "# Turn all comic text data into tf-idf vectors \n",
    "########################################################################################################################\n",
    "\n",
    "vectorizer = TfidfVectorizer(norm='l2',min_df=0, use_idf=True, smooth_idf=False, sublinear_tf=True, tokenizer=word_tokenize,lowercase=True)\n",
    "vectorizer = vectorizer.fit(df['all_text'].str.lower()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "title_vectors = vectorizer.transform(df['title'])\n",
    "rollover_vectors = vectorizer.transform(df['title_text'])\n",
    "category_vectors = vectorizer.transform(df['all_categories'])\n",
    "explanation_vectors = vectorizer.transform(df['explanation'])\n",
    "transcript_vectors = vectorizer.transform(df['transcript'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(398, 5) (398, 5)\n"
     ]
    }
   ],
   "source": [
    "########################################################################################################################\n",
    "# Get the similarity score matrix between a query and comic texts \n",
    "########################################################################################################################\n",
    "query = ['debugging']\n",
    "query_vec = vectorizer.transform(query)\n",
    "\n",
    "def jaccard_similarity(str1,str2):\n",
    "    str1 = set(word_tokenize(str1))\n",
    "    str2 = set(word_tokenize(str2))\n",
    "    return float(len(str1 & str2)) / float(len(str1 | str2)) \n",
    "\n",
    "title_sim = cosine_similarity(query_vec,title_vectors).transpose()\n",
    "rollover_sim = cosine_similarity(query_vec,rollover_vectors).transpose()\n",
    "category_sim = cosine_similarity(query_vec,category_vectors).transpose()\n",
    "explanation_sim = cosine_similarity(query_vec,explanation_vectors).transpose()\n",
    "transcript_sim = cosine_similarity(query_vec,transcript_vectors).transpose()\n",
    "\n",
    "jaccard_title = np.array([jaccard_similarity(query[0],string) for string in df['title']]).reshape((len(df['title']),1))\n",
    "jaccard_rollover = np.array([jaccard_similarity(query[0],string) for string in df['title_text']]).reshape((len(df['title']),1))\n",
    "jaccard_category = np.array([jaccard_similarity(query[0],string) for string in df['all_categories']]).reshape((len(df['title']),1))\n",
    "jaccard_explanation = np.array([jaccard_similarity(query[0],string) for string in df['explanation']]).reshape((len(df['title']),1))\n",
    "jaccard_transcript = np.array([jaccard_similarity(query[0],string) for string in df['transcript']]).reshape((len(df['title']),1))\n",
    "\n",
    "score_matrix = np.column_stack((title_sim,rollover_sim,category_sim,explanation_sim,transcript_sim))\n",
    "jaccard_matrix = np.column_stack((jaccard_title,jaccard_rollover,jaccard_category,jaccard_explanation,jaccard_transcript))\n",
    "\n",
    "print(jaccard_matrix.shape,score_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULT #1 :  1722: Debugging \n",
      " title                                               1722: Debugging\n",
      "url               http://www.explainxkcd.com/wiki/index.php/1722...\n",
      "title_text        When you Google an error message and it gets n...\n",
      "explanation       Cueball is telling White Hat about his attempt...\n",
      "transcript        [Cueball and White Hat are walking, while Cueb...\n",
      "all_text          1722: Debugging computers When you Google an e...\n",
      "all_categories                                            computers\n",
      "Name: 119, dtype: object \n",
      "\n",
      "RESULT #2 :  979: Wisdom of the Ancients \n",
      " title                                   979: Wisdom of the Ancients\n",
      "url               http://www.explainxkcd.com/wiki/index.php/979:...\n",
      "title_text        All long help threads should have a sticky glo...\n",
      "explanation       This comic refers to a common experience that ...\n",
      "transcript        [A poem is written outside and right justified...\n",
      "all_text          979: Wisdom of the Ancients computers All long...\n",
      "all_categories                     computers internet google_search\n",
      "Name: 203, dtype: object \n",
      "\n",
      "RESULT #3 :  1629: Tools \n",
      " title                                                   1629: Tools\n",
      "url               http://www.explainxkcd.com/wiki/index.php/1629...\n",
      "title_text        I make tools for managing job-hunting sites fo...\n",
      "explanation       Cueball asks Megan what she does, and she begi...\n",
      "transcript        [Cueball talks to Megan.] Cueball: What do you...\n",
      "all_text          1629: Tools computers I make tools for managin...\n",
      "all_categories                                computers programming\n",
      "Name: 108, dtype: object \n",
      "\n",
      "[ 0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.0890805   0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  3.84699548  0.          0.          0.          0.08799545  0.0808328   0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.09397831  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.06749904  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.07802054  0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "weights = np.array([5,3,6,1,3]) # Weights in order title, rollover, category, explanation, transcript\n",
    "j_weights = np.array([20,1,1,1,40])\n",
    "results = np.matmul(score_matrix,weights)\n",
    "# results = np.matmul(jaccard_matrix,j_weights)\n",
    "\n",
    "count = 1\n",
    "for idx in results.argsort()[:-4:-1]:\n",
    "    print(\"RESULT #%i\" % count,\": \",df['title'].loc[idx],\"\\n\",df.loc[idx],\"\\n\")\n",
    "    count += 1\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
